{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Q_FDVFtrK8ko"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ekagglehub) (3.4.3)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ekagglehub) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ekagglehub) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ekagglehub) (2025.8.3)\n","Using Colab cache for faster access to the 'car-parts-and-car-damages' dataset.\n","Датасет Kaggle скачан в: /kaggle/input/car-parts-and-car-damages\n","\n","Содержимое папки Kaggle:\n","'Car damages dataset'  'Car parts dataset'\n","Traceback (most recent call last):\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1331, in _find_and_load_unlocked\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 935, in _load_unlocked\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 999, in exec_module\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 488, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/build_env.py\", line 21, in \u003cmodule\u003e\n","    from pip._internal.metadata import get_default_environment, get_environment\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/__init__.py\", line 9, in \u003cmodule\u003e\n","    from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/base.py\", line 38, in \u003cmodule\u003e\n","    from pip._internal.utils.egg_link import egg_link_path_from_sys_path\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1360, in _find_and_load\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1331, in _find_and_load_unlocked\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 935, in _load_unlocked\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 995, in exec_module\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 1128, in get_code\n","  File \"\u003cfrozen importlib._bootstrap_external\u003e\", line 757, in _compile_bytecode\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 4, in \u003cmodule\u003e\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 11, in \u003cmodule\u003e\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in \u003cmodule\u003e\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in \u003cmodule\u003e\n","    from pip._internal.build_env import get_runnable_pip\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1360, in _find_and_load\n","  File \"\u003cfrozen importlib._bootstrap\u003e\", line 1334, in _find_and_load_unlocked\n","KeyboardInterrupt\n","^C\n","loading Roboflow workspace...\n","loading Roboflow project...\n","Датасет Roboflow успешно скачан в: /content/less-than-640-2\n","\n","Содержимое папки Roboflow:\n","README.dataset.txt  README.roboflow.txt  train\tvalid\n"]}],"source":["!pip install kagglehub\n","import kagglehub\n","import os\n","\n","kaggle_path = kagglehub.dataset_download(\"humansintheloop/car-parts-and-car-damages\")\n","print(\"Датасет Kaggle скачан в:\", kaggle_path)\n","print(\"\\nСодержимое папки Kaggle:\")\n","!ls {kaggle_path}\n","\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"RHcpuYZ2kGtOP3mq8eyT\")\n","project = rf.workspace(\"dirty\").project(\"less-than-640\")\n","version = project.version(2)\n","roboflow_dataset = version.download(\"folder\")\n","\n","\n","print(\"Датасет Roboflow успешно скачан в:\", roboflow_dataset.location)\n","\n","# Проверяем содержимое папки, чтобы убедиться, что все на месте\n","print(\"\\nСодержимое папки Roboflow:\")\n","!ls {roboflow_dataset.location}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"wV7YHT_a4pbh"},"outputs":[],"source":["# Устанавливаем PyTorch и другие библиотеки при необходимости (скриптовый способ, работает и в Colab)\n","import sys, subprocess\n","try:\n","    import torch  # noqa: F401\n","    import torchvision  # noqa: F401\n","    import torchaudio  # noqa: F401\n","except Exception:\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"torchaudio\"])\n","\n","import os\n","import math\n","import copy\n","import random\n","from typing import Dict, Tuple\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision import datasets, models, transforms\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","# Пути к данным, которые ты скачал с Roboflow\n","# Примечание: путь ниже рассчитан на Google Colab. Замени при необходимости.\n","data_dir = '/content/less-than-640-2'\n","train_dir = os.path.join(data_dir, 'train')\n","val_dir = os.path.join(data_dir, 'valid')\n","\n","# Фиксируем сиды для воспроизводимости (по возможности)\n","def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = False  # True замедляет, но детерминирует\n","    torch.backends.cudnn.benchmark = True\n","\n","set_seed(42)\n","\n","# Определяем преобразования для изображений (минимальные без аугментаций)\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Создаем объекты датасетов\n","image_datasets = {\n","    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n","    'val': datasets.ImageFolder(val_dir, data_transforms['val'])\n","}\n","\n","# Удаляем класс 'Unlabeled' (если присутствует) из наборов\n","def remove_class_from_imagefolder(ds: datasets.ImageFolder, class_name: str = 'Unlabeled') -\u003e datasets.ImageFolder:\n","    if class_name not in ds.class_to_idx:\n","        return ds\n","    remove_idx = ds.class_to_idx[class_name]\n","    new_classes = [c for c in ds.classes if c != class_name]\n","    new_class_to_idx = {c: i for i, c in enumerate(new_classes)}\n","\n","    new_samples = []\n","    new_targets = []\n","    removed = 0\n","    for path, old_y in ds.samples:\n","        if old_y == remove_idx:\n","            removed += 1\n","            continue\n","        class_name_for_old = ds.classes[old_y]\n","        new_y = new_class_to_idx[class_name_for_old]\n","        new_samples.append((path, new_y))\n","        new_targets.append(new_y)\n","\n","    ds.samples = new_samples\n","    ds.imgs = new_samples\n","    ds.targets = new_targets\n","    ds.classes = new_classes\n","    ds.class_to_idx = new_class_to_idx\n","    print(f\"Removed class '{class_name}': {removed} samples removed.\")\n","    return ds\n","\n","# Применяем фильтрацию\n","image_datasets['train'] = remove_class_from_imagefolder(image_datasets['train'], 'Unlabeled')\n","image_datasets['val'] = remove_class_from_imagefolder(image_datasets['val'], 'Unlabeled')\n","\n","# Оценим дисбаланс классов и при необходимости используем WeightedRandomSampler\n","def build_train_sampler_if_needed(dataset: datasets.ImageFolder, imbalance_threshold: float = 1.5):\n","    # Считаем количество образцов по классам\n","    targets = [y for _, y in dataset.samples]\n","    class_counts = {}\n","    for y in targets:\n","        class_counts[y] = class_counts.get(y, 0) + 1\n","    max_c = max(class_counts.values())\n","    min_c = min(class_counts.values())\n","    ratio = max_c / max(1, min_c)\n","    if ratio \u003e= imbalance_threshold:\n","        class_weights = {c: (1.0 / count) for c, count in class_counts.items()}\n","        sample_weights = [class_weights[y] for y in targets]\n","        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n","        return sampler, class_counts, ratio\n","    return None, class_counts, ratio\n","\n","train_sampler, class_counts, imbalance_ratio = build_train_sampler_if_needed(image_datasets['train'])\n","\n","# Создаем загрузчики данных\n","dataloaders = {\n","    'train': DataLoader(\n","        image_datasets['train'], batch_size=32,\n","        shuffle=(train_sampler is None), sampler=train_sampler,\n","        num_workers=4, pin_memory=True\n","    ),\n","    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n","}\n","\n","# Определяем размер датасетов (после фильтрации)\n","dataset_sizes = {\n","    'train': len(image_datasets['train']),\n","    'val': len(image_datasets['val'])\n","}\n","\n","# Получаем имена классов (после фильтрации)\n","class_names = image_datasets['train'].classes\n","print(\"Имена классов:\", class_names)\n","print(\"Размер обучающего набора:\", dataset_sizes['train'])\n","print(\"Размер валидационного набора:\", dataset_sizes['val'])\n","print(\"Распределение классов (train):\", {class_names[c]: n for c, n in class_counts.items()})\n","if imbalance_ratio \u003e= 1.5:\n","    print(f\"Обнаружен дисбаланс классов ≈ {imbalance_ratio:.2f}×. Включен WeightedRandomSampler.\")\n","\n","# Проверка согласованности наборов классов между train и val\n","if set(image_datasets['train'].classes) != set(image_datasets['val'].classes):\n","    raise RuntimeError(\n","        f\"Наборы классов в train и val отличаются. train={image_datasets['train'].classes}, val={image_datasets['val'].classes}.\\n\"\n","        \"Убедись, что папки классов совпадают (например, только 'clean' и 'dirty').\"\n","    )\n","\n","# Проверяем, доступен ли GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Используемое устройство:\", device)\n","\n","# Загружаем предобученную модель ResNet-50\n","model_ft = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n","\n","# Заменяем последний слой, чтобы он соответствовал нашему количеству классов\n","num_ftrs = model_ft.fc.in_features\n","# Добавим Dropout перед последним слоем как легкую регуляризацию\n","model_ft.fc = nn.Sequential(\n","    nn.Dropout(p=0.2),\n","    nn.Linear(num_ftrs, len(class_names))\n",")\n","\n","# Перемещаем модель на GPU, если он доступен\n","model_ft = model_ft.to(device)\n","\n","# Определяем функцию потерь (loss function) и оптимизатор\n","# Если сильный дисбаланс — используем взвешенную функцию потерь\n","if imbalance_ratio \u003e= 1.5:\n","    weights_list = [1.0 / max(1, class_counts.get(i, 1)) for i in range(len(class_names))]\n","    class_weights = torch.tensor(weights_list, dtype=torch.float32, device=device)\n","    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n","    print(f\"Используем взвешенную CrossEntropyLoss с весами: {weights_list}\")\n","else:\n","    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","\n","# Дифференцированные скорости обучения: голова — быстрее, спина — медленнее\n","backbone_params = []\n","head_params = []\n","for name, p in model_ft.named_parameters():\n","    if name.startswith('fc.'):\n","        head_params.append(p)\n","    else:\n","        backbone_params.append(p)\n","\n","optimizer_ft = optim.AdamW([\n","    {\"params\": backbone_params, \"lr\": 1e-4},\n","    {\"params\": head_params, \"lr\": 1e-3},\n","], weight_decay=1e-4)\n","\n","# План понижения lr (плавное) — косинусная схема\n","# Подгоним период косинусного расписания под планируемое число эпох\n","scheduler = CosineAnnealingLR(optimizer_ft, T_max=20)\n","\n","def train_model(\n","    model: nn.Module,\n","    criterion: nn.Module,\n","    optimizer: optim.Optimizer,\n","    scheduler: torch.optim.lr_scheduler._LRScheduler,\n","    num_epochs: int = 15,\n","    patience: int = 5,\n","    use_amp: bool = True,\n","    freeze_epochs: int = 2,\n",") -\u003e Tuple[nn.Module, Dict[str, float]]:\n","    \"\"\"\n","    Функция для обучения модели с ранней остановкой и сохранением лучшей версии по валидации.\n","    Возвращает лучшую модель и словарь метрик.\n","    \"\"\"\n","    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n","\n","    best_acc = 0.0\n","    best_loss = math.inf\n","    best_wts = copy.deepcopy(model.state_dict())\n","    epochs_no_improve = 0\n","\n","    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n","\n","    # Фаза с заморозкой бэкбона (кроме головы) — стабилизация обучения на малых датасетах\n","    def set_backbone_trainable(is_trainable: bool):\n","        for name, p in model.named_parameters():\n","            if not name.startswith('fc.'):\n","                p.requires_grad = is_trainable\n","\n","    if freeze_epochs \u003e 0:\n","        set_backbone_trainable(False)\n","        print(f\"Backbone заморожен на первые {freeze_epochs} эпох(и).\")\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device, non_blocking=True)\n","                labels = labels.to(device, non_blocking=True)\n","\n","                optimizer.zero_grad(set_to_none=True)\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    with torch.cuda.amp.autocast(enabled=use_amp):\n","                        outputs = model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        scaler.scale(loss).backward()\n","                        # Опционально: клиппинг градиентов для стабильности\n","                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            history[f\"{phase}_loss\"].append(epoch_loss)\n","            history[f\"{phase}_acc\"].append(epoch_acc.item())\n","\n","            if phase == 'val':\n","                # шаг планировщика после валидации за эпоху\n","                scheduler.step()\n","\n","                improved = epoch_acc.item() \u003e best_acc\n","                if improved:\n","                    best_acc = epoch_acc.item()\n","                    best_loss = epoch_loss\n","                    best_wts = copy.deepcopy(model.state_dict())\n","                    epochs_no_improve = 0\n","                    torch.save(best_wts, 'resnet_car_classifier_best.pth')\n","                    print('✓ Сохранена новая лучшая модель (по val Acc).')\n","                else:\n","                    epochs_no_improve += 1\n","                    if epochs_no_improve \u003e= patience:\n","                        print(f'Ранняя остановка: без улучшений {epochs_no_improve} эпох подряд.')\n","                        model.load_state_dict(best_wts)\n","                        return model, {\"best_val_acc\": best_acc, \"best_val_loss\": best_loss}\n","\n","        # По окончании эпохи размораживаем бэкбон, если подошло время\n","        if freeze_epochs \u003e 0 and epoch + 1 == freeze_epochs:\n","            set_backbone_trainable(True)\n","            print(\"Backbone разморожен для дальнейшего дообучения.\")\n","\n","        # Печатаем текущие LR для наглядности\n","        lrs = [group['lr'] for group in optimizer.param_groups]\n","        print('LRs:', [f\"{lr:.2e}\" for lr in lrs])\n","\n","    model.load_state_dict(best_wts)\n","    return model, {\"best_val_acc\": best_acc, \"best_val_loss\": best_loss}\n","\n","# Запускаем обучение\n","model_trained, metrics = train_model(\n","    model_ft, criterion, optimizer_ft, scheduler,\n","    num_epochs=20, patience=5, use_amp=torch.cuda.is_available(), freeze_epochs=2,\n",")\n","\n","# Сохраняем финальную (лучшую) модель\n","torch.save(model_trained.state_dict(), 'resnet_car_classifier.pth')\n","print(\"Модель успешно сохранена! Лучшая по валидации также сохранена как 'resnet_car_classifier_best.pth'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sx06NZQpP7q4"},"outputs":[],"source":["# Загружаем модель\n","best_model_path = 'resnet_car_classifier_best.pth'\n","model_trained = model_ft\n","map_location = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model_trained.load_state_dict(torch.load(best_model_path, map_location=map_location))\n","model_trained.eval()\n","\n","# Проверяем количество классов в модели и в датасете\n","num_model_classes = model_trained.fc[-1].out_features\n","num_dataloader_classes = len(val_dataloader.dataset.classes)\n","\n","if num_model_classes != num_dataloader_classes:\n","    raise ValueError(f\"Несоответствие количества классов! Модель обучена на {num_model_classes} классах, а в датасете {num_dataloader_classes} классов.\")\n","\n","# Теперь запускаем визуализацию\n","visualize_results(model_trained, val_dataloader, class_names, map_location)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNmvA+Lf/KhuQ+4LEh5Oio4","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}